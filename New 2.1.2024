# Project-EP-Topic-11
# Part 1: Task 1-5

import numpy as np
import matplotlib.pyplot as plt
import rasterio
import pandas as pd
import matplotlib.patches as mpatches

# -------------------------------------------------------------------------------
# Task 1: Open the natural hazard, slope, and stream network maps as numpy arrays
natural_hazard_path = '/content/NH_EVENT_DETECTION.tif'
slope_map_path = '/content/Slope.tif'
stream_network_path = '/content/Stream_Network.tif'

# Function to open a GeoTIFF file and return its data as a numpy array
def open_geotiff(file_path):
    with rasterio.open(file_path) as src:
        return src.read(1)  # Assuming a single band GeoTIFF

# Open the maps as numpy arrays
natural_hazard_map = open_geotiff(natural_hazard_path)
slope_map = open_geotiff(slope_map_path)
stream_network_map = open_geotiff(stream_network_path)

# Print the numpy array results
print("Natural Hazard Array:")
print(natural_hazard_map)
print("\nSlope Array:")
print(slope_map)
print("\nStream Network Array:")
print(stream_network_map)

# ------------------------------------------------------------------------------------
# Task 2: Visualize the slope and stream network map and export them as 600 dpi images
def visualize_and_export(image, output_path, title):
    plt.figure(figsize=(10, 10))
    plt.imshow(image, cmap='viridis')
    plt.colorbar()
    plt.title(title)  # Setting the title of the plot
    plt.axis('off')
    plt.savefig(output_path, dpi=600, bbox_inches='tight')
    plt.show()
# Visualize and export the slope map 
visualize_and_export(slope_map, 'slope_map.png', 'Slope Map')

# Visualize and export the stream network map
visualize_and_export(stream_network_map, 'stream_network_map.png', 'Stream Network Map')

# ------------------------------------------------------------------------------------------------------------------
# Task 3: Create a function that ingests the NH map and makes a binary map (0/1) for non-affected and affected areas
# Create a binary numpy array with 0/1 values
def binary_map(natural_hazard_map, threshold):
    binary_map = np.where(natural_hazard_map >= threshold, 1, 0)
    return binary_map
user_threshold = 0.5  # Replace with the user's chosen threshold
binary_map_result = binary_map(natural_hazard_map, user_threshold)
print(binary_map_result)

# Create binary map
plt.figure(figsize=(10, 10))
plt.imshow(binary_map_result, cmap='binary', interpolation='nearest')
cbar = plt.colorbar()
cbar.set_ticks([0, 1])
cbar.set_ticklabels(['0 Non-affected', '1 Affected'])
plt.title('Binary Hazard Map')
plt.axis('off')
plt.show()


# --------------------------------------------------------
# Task 4: Discriminate landslide and flash flood locations

def discriminate_locations(nh_map, slope_map, stream_network_map):
    # Define landslide area: slope between 20 and 70 and NH map > 0.5
    landslide_area = np.logical_and(slope_map >= 20, slope_map <= 70)
    landslide_locations = np.logical_and(landslide_area, nh_map > 0.5)

    # Define flood area: stream network > 4 and NH map > 0.5
    flood_area = stream_network_map > 4
    flood_locations = np.logical_and(flood_area, nh_map > 0.5)

    return landslide_locations, flood_locations

# ---------------------------------------------------------------------
# Task 5: Create and export maps showing only landslide and flood areas
landslide_map, flood_map = discriminate_locations(natural_hazard_map, slope_map, stream_network_map)
# Function to visualize and export map
def visualize_and_export(image, output_path, title, colorbar_labels):
    plt.figure(figsize=(10, 10))
    img = plt.imshow(image, cmap='viridis')
    cbar = plt.colorbar(img, ticks=[np.min(image), np.max(image)])
    cbar.set_ticklabels(colorbar_labels)
    plt.axis('off')
    plt.title(title)
    plt.savefig(output_path, dpi=600, bbox_inches='tight')
    plt.show()

# Define the labels for the legends
landslide_colorbar_labels = ['No Risk', 'Landslide Risk']
flood_colorbar_labels = ['No Risk', 'Flood Risk']
# Visualize and export
visualize_and_export(landslide_map, 'landslide_area_map.png', 'Landslide Risk Areas', landslide_colorbar_labels)
visualize_and_export(flood_map, 'flash_flood_area_map.png', 'Flash Flood Risk Areas', flood_colorbar_labels)

# Part 2: Task 6-9

import os
from rasterio.plot import show
from rasterio.windows import Window
from rasterio.enums import Resampling
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd
from datetime import datetime


# -----------------------------------------
# Task 6: Read time series of rainfall maps
rainfall_folder = '/content/Rainfall/'

# List all rainfall files in the folder
rainfall_files = [f for f in os.listdir(rainfall_folder) if f.endswith('.tif')]
rainfall_files.sort()  # Sort files to ensure correct temporal order

# Read the first rainfall map to get metadata
with rasterio.open(os.path.join(rainfall_folder, rainfall_files[0])) as src:
    meta = src.meta
    rain_data_shape = src.shape

# Initialize an array to store all rainfall maps
rainfall_data = np.zeros((len(rainfall_files), rain_data_shape[0], rain_data_shape[1]), dtype=np.float32)

# Read all rainfall maps into the array
for i, rainfall_file in enumerate(rainfall_files):
    with rasterio.open(os.path.join(rainfall_folder, rainfall_file)) as src:
        resampled_data = src.read(out_shape=(rain_data_shape[0], rain_data_shape[1]), resampling=Resampling.bilinear)
        rainfall_data[i, :, :] = resampled_data


# -----------------------------------------------------------------
# Task 7: Plot the spatially averaged daily rainfall as time series
# Calculate spatially averaged daily rainfall
spatially_averaged_rainfall = np.mean(rainfall_data, axis=(1, 2))

# Assuming filenames are in the format 'YYYY-MM-DD_Rainfall.tif'
def extract_date_from_filename(filename):
    date_str = filename.split('_')[0]  # Get the date part before '_'
    return datetime.strptime(date_str, '%Y-%m-%d')

# Read the dates from filenames
rainfall_dates = [extract_date_from_filename(f) for f in rainfall_files]

# Plot time series with DD-MM format dates
plt.figure(figsize=(12, 6))
plt.plot(rainfall_dates, spatially_averaged_rainfall, marker='o', linestyle='-', color='b')
plt.title('Spatially Averaged Daily Rainfall Time Series')
plt.xlabel('Date')
plt.ylabel('Rainfall (mm)')
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m'))
plt.gca().xaxis.set_major_locator(mdates.DayLocator())
plt.gcf().autofmt_xdate()  # Auto-format the dates for better readability
plt.grid(True)
plt.show()

# --------------------------
# Task 8: Create function that calculates rainfall stats for whole area: X-day average/median/max/sum

def rainfall_statistics(rainfall_data, x_days, date_index, before=True):
    # Determine the start and end indices for the data slice
    if before:
        start_index = max(date_index - x_days + 1, 0)
        end_index = date_index + 1
    else:
        start_index = date_index + 1
        end_index = min(date_index + 1 + x_days, len(rainfall_data))

    # Slice the rainfall data
    data_slice = rainfall_data[start_index:end_index]

    # Calculate statistics
    mean_rainfall = np.mean(data_slice)
    median_rainfall = np.median(data_slice)
    max_rainfall = np.max(data_slice)
    sum_rainfall = np.sum(data_slice)

    return mean_rainfall, median_rainfall, max_rainfall, sum_rainfall

# Task 9:  The event occurred on 17-04-2020 (index = 4, 5th day)
# Event date index (example: 4 for the 5th day)
event_date_index = 4

# List to hold all statistics
all_stats = []

# Loop to calculate statistics
# Loop to calculate statistics for 1, 2, and 3 days before and after the event
for x in [1, 2, 3]:
    for period in ['Before', 'After']:
        mean, median, max_, sum_ = rainfall_statistics(rainfall_data, x, event_date_index, period == 'Before')

        if period == 'Before':
            stat_date = rainfall_dates[event_date_index - x]  # Adjusted to correctly reflect 'Before' period
        else:
            stat_date = rainfall_dates[min(event_date_index + x, len(rainfall_data) - 1)]  # 'After' period

        # Append statistics to the list
        all_stats.append((stat_date, period, x, mean, median, max_, sum_))

# Convert to DataFrame
columns = ['Date', 'Period', 'Days', 'Mean', 'Median', 'Max', 'Sum']
final_results = pd.DataFrame(all_stats, columns=columns)

# Export to CSV
csv_file_path = 'final_results.csv'
final_results.to_csv(csv_file_path, index=False)

